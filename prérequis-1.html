<!DOCTYPE html>
<html lang="fr">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapitre 6 Prérequis | Analyser des données avec R</title>
<meta name="author" content="Pierre-Yves de Müllenheim">
<meta name="description" content="6.1 Préambule Réaliser une inférence statistique consiste à conclure à propos de quelque chose dans une population d’intérêt (cette chose pouvant se traduire par n’importe quel paramètre...">
<meta name="generator" content="bookdown 0.36 with bs4_book()">
<meta property="og:title" content="Chapitre 6 Prérequis | Analyser des données avec R">
<meta property="og:type" content="book">
<meta property="og:url" content="https://github.com/pydemull/Analyser-des-donnees-avec-R/prérequis-1.html">
<meta property="og:description" content="6.1 Préambule Réaliser une inférence statistique consiste à conclure à propos de quelque chose dans une population d’intérêt (cette chose pouvant se traduire par n’importe quel paramètre...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapitre 6 Prérequis | Analyser des données avec R">
<meta name="twitter:description" content="6.1 Préambule Réaliser une inférence statistique consiste à conclure à propos de quelque chose dans une population d’intérêt (cette chose pouvant se traduire par n’importe quel paramètre...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.5.1/transition.js"></script><script src="libs/bs3compat-0.5.1/tabs.js"></script><script src="libs/bs3compat-0.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><link href="libs/tabwid-1.1.3/tabwid.css" rel="stylesheet">
<script src="libs/tabwid-1.1.3/tabwid.js"></script><!-- Code fom Dexter to custom bs4_book template: https://stackoverflow.com/questions/66128954/change-right-sidebar-header-in-bs4-book-bookdown --><script>
        $(function() {
            $("#toc h2").html("Dans ce chapitre");
        });
    </script><script>
        $(function() {
            $("#main-nav h2").html("Sommaire");
        });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Analyser des données avec R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Introduction</a></li>
<li class="book-part">Appropriation de R et RStudio</li>
<li><a class="" href="pr%C3%A9requis.html"><span class="header-section-number">1</span> Prérequis</a></li>
<li><a class="" href="importation-et-manipulation-dune-base-de-donn%C3%A9es.html"><span class="header-section-number">2</span> Importation et manipulation d’une base de données</a></li>
<li class="book-part">Analyses descriptives</li>
<li><a class="" href="analyses-univari%C3%A9es.html"><span class="header-section-number">3</span> Analyses univariées</a></li>
<li><a class="" href="analyses-bivari%C3%A9es.html"><span class="header-section-number">4</span> Analyses bivariées</a></li>
<li><a class="" href="r%C3%A9gressions.html"><span class="header-section-number">5</span> Régressions</a></li>
<li class="book-part">Analyses inférentielles</li>
<li><a class="active" href="pr%C3%A9requis-1.html"><span class="header-section-number">6</span> Prérequis</a></li>
<li><a class="" href="tests-statistiques-pour-des-variables-qualitatives.html"><span class="header-section-number">7</span> Tests statistiques pour des variables qualitatives</a></li>
<li><a class="" href="r%C3%A9f%C3%A9rences.html">Références</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/pydemull/Analyser-des-donnees-avec-R">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="prérequis-1" class="section level1" number="6">
<h1>
<span class="header-section-number">Chapitre 6</span> Prérequis<a class="anchor" aria-label="anchor" href="#pr%C3%A9requis-1"><i class="fas fa-link"></i></a>
</h1>
<div id="préambule" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Préambule<a class="anchor" aria-label="anchor" href="#pr%C3%A9ambule"><i class="fas fa-link"></i></a>
</h2>
<p>Réaliser une inférence statistique consiste à conclure à propos de quelque chose dans une population d’intérêt (cette chose pouvant se traduire par n’importe quel paramètre statistique : une moyenne, une médiane, une proportion, un coefficient de corrélation, une différence de moyennes, un rapport de cotes, etc.), cela à partir de données prélevées dans un échantillon de cette population. Pour comprendre la mécanique des calculs à mettre en oeuvre pour réaliser une inférence statistique, il est nécessaire d’avoir quelques notions en matière de probabilité. Ce chapitre, qui s’inspire largement du chapitre “Introduction to probability” de l’ouvrage de Danielle Navarro <span class="citation">(<a href="r%C3%A9f%C3%A9rences.html#ref-navarroLearningStatistics2018" role="doc-biblioref">2018</a>)</span>, vise à présenter brièvement ces notions.</p>
</div>
<div id="lois-de-probabilité" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Lois de probabilité<a class="anchor" aria-label="anchor" href="#lois-de-probabilit%C3%A9"><i class="fas fa-link"></i></a>
</h2>
<div id="notion-de-loi-de-probabilité" class="section level3" number="6.2.1">
<h3>
<span class="header-section-number">6.2.1</span> Notion de loi de probabilité<a class="anchor" aria-label="anchor" href="#notion-de-loi-de-probabilit%C3%A9"><i class="fas fa-link"></i></a>
</h3>
<p>Les procédures de calcul pour réaliser une inférence statistique requièrent d’utiliser des lois mathématiques que l’on doit configurer pour déterminer théoriquement les probabilités de rencontrer telle ou telle valeur d’un paramètre statistique donné lorsqu’on étudie un échantillon provenant de la population d’intérêt. Cette démarche implique de comprendre que si un phénomène existe (ou pas) à l’échelle d’une population (chose quantifiable à l’aide de la valeur d’un paramètre statistique donné), l’étude d’un échantillon provenant de cette population ne donnera pas forcément la même valeur pour le paramètre statistique considéré. L’enjeu est alors de pouvoir déterminer la probabilité qui était celle d’obtenir telle ou telle valeur du paramètre statistique considéré avec son échantillon dans le cas où le phénomène étudié existerait (ou pas), cela pour envisager une conclusion quant à la réelle existence ou non du phénomène étudié dans la population d’intérêt.</p>
<p>Ces lois mathématiques utilisées pour faire des inférences statistiques, qu’on appelle aussi des lois de probabilité, donnent directement les valeurs de probabilité d’obtenir telle ou telle valeur du paramètre statistique considéré dans les cas de variables qualitatives. Dans les cas de variables quantitatives, les lois de probabilité ne donnent pas directement les probabilités. En effet, dans ces situations, les lois donnent les <strong>densités de probabilité</strong>. Ceci est lié au fait que dans ce type de situations, les probabilités concernent le fait d’avoir des valeurs appartenant à des intervalles donnés, et non pas d’avoir une valeur précise. Cela implique que pour obtenir la probabilité de rencontrer une valeur appartenant à un intervalle donné, il ne faut pas prendre la valeur directement donnée par la loi de probabilité, mais l’intégrale (i.e., l’aire sous la courbe de densité de probabilité) correspondant à l’intervalle de valeurs considéré. Ce qui suit vise à décrire et illustrer des lois de probabilité typiquement utilisées dans les procédures de calcul servant à réaliser des inférences statistiques.</p>
</div>
<div id="la-loi-binomiale" class="section level3" number="6.2.2">
<h3>
<span class="header-section-number">6.2.2</span> La loi binomiale<a class="anchor" aria-label="anchor" href="#la-loi-binomiale"><i class="fas fa-link"></i></a>
</h3>
<p>La loi binomiale est une loi mathématique qui concerne les situations où seulement deux résultats sont possibles, comme par exemple “succès” et “échec”, “pile” et “face”, “0” et “1”, etc. Un exemple classique où l’on est en présence d’une variable binomiale est celui où l’on demande à <span class="math inline">\(N\)</span> personnes de lancer une fois une pièce non truquée, avec par conséquent “pile” et “face” comme seuls résultats possibles et autant de chances de tomber sur “pile” que sur “face” à chaque lancer (<span class="math inline">\(\theta\)</span> = 0.5, soit une chance sur deux). Une fois les essais de toutes les personnes terminés, la distribution qui en résulte contient alors la proportion de personnes qui ont obtenu “pile” et la proportion de personnes qui n’ont pas obtenu “pile” (donc “face”). Lorsque le nombre <span class="math inline">\(N\)</span> d’essais ou de participants et la probabilité d’avoir tel ou tel résultat (<span class="math inline">\(\theta\)</span>) sont connus, la loi binomiale, qu’on note <span class="math inline">\(X \sim B(\theta, N)\)</span>, permet de connaître la probabilité <span class="math inline">\(P(X)\)</span> d’avoir <span class="math inline">\(X\)</span> succès (e.g., <span class="math inline">\(X\)</span> fois “pile”) sur les <span class="math inline">\(N\)</span> essais ou participants. La formule de cette loi est montrée ci-dessous :</p>
<p><span class="math display">\[P(X | \theta, N) = \frac{N!}{X!(N-X)!}\theta^X(1-\theta)^{N-X}\]</span></p>
<p>La Figure <a href="pr%C3%A9requis-1.html#fig:distriBinom">6.1</a> illustre une loi binomiale (avec <span class="math inline">\(N\)</span> = 100 et <span class="math inline">\(\theta\)</span> = 0.5) qui pourrait s’appliquer au cas d’un lancer de pièce non truquée. Cette figure montre que même si une pièce est non truquée (<span class="math inline">\(\theta\)</span> = 0.5), il est tout à fait possible qu’il y ait plus de personnes à obtenir “pile” plutôt que “face” et inversement sur un échantillon de 100 personnes. Cependant, ce que montre aussi la figure, c’est que si la pièce est non truquée, les chances restent les plus fortes pour l’obtention de 50 % de personnes avec “pile” et avec “face” pour un lancer de pièce.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:distriBinom"></span>
<img src="Analyser-des-donne%CC%81es-avec-R_files/figure-html/distriBinom-1.png" alt="Illustration d'une loi binomiale avec la situation de 100 personnes lançant une pièce non truquée" width="80%"><p class="caption">
Figure 6.1: Illustration d’une loi binomiale avec la situation de 100 personnes lançant une pièce non truquée
</p>
</div>
<p>Plusieurs fonctions R peuvent être utilisées pour obtenir des informations liées aux probabilités données par une loi binomiale. Ces fonctions sont montrées ci-dessous.</p>
<div class="sourceCode" id="cb251"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fonction pour déterminer la probabilité d'obtenir précisément x succès </span></span>
<span><span class="co"># (ici 50) à partir de N essais/personnes (ici 100) et d'une probabilité </span></span>
<span><span class="co"># de succès donnée (ici 0.5)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">50</span>, size <span class="op">=</span> <span class="fl">100</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.07958924</code></pre>
<div class="sourceCode" id="cb253"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fonction pour déterminer la probabilité d'obtenir un nombre de succès</span></span>
<span><span class="co"># inférieur ou égal à q (ici 50) à partir de N essais/personnes (ici 100) </span></span>
<span><span class="co"># et d'une probabilité de succès donnée (ici 0.5)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">pbinom</a></span><span class="op">(</span>q <span class="op">=</span> <span class="fl">50</span>, size <span class="op">=</span> <span class="fl">100</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.5397946</code></pre>
<div class="sourceCode" id="cb255"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fonction pour déterminer la valeur pour laquelle il y a une probabilité p </span></span>
<span><span class="co"># d'obtenir une valeur inférieure ou égale à la valeur définie à partir de N </span></span>
<span><span class="co"># essais/personnes (ici 100) et d'une probabilité de succès donnée (ici 0.5)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">qbinom</a></span><span class="op">(</span>p <span class="op">=</span> <span class="fl">0.6</span>, size <span class="op">=</span> <span class="fl">100</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 51</code></pre>
</div>
<div id="la-loi-normale-et-lois-apparentées" class="section level3" number="6.2.3">
<h3>
<span class="header-section-number">6.2.3</span> La loi normale et lois apparentées<a class="anchor" aria-label="anchor" href="#la-loi-normale-et-lois-apparent%C3%A9es"><i class="fas fa-link"></i></a>
</h3>
<p>La <strong>loi normale</strong>, ou encore <strong>loi gaussienne</strong>, qu’on note <span class="math inline">\(X \sim N(\mu, \sigma)\)</span>, avec <span class="math inline">\(\mu\)</span> la moyenne de la variable, et <span class="math inline">\(\sigma\)</span> l’écart-type de la variable, est une loi qui permet de déterminer la probabilité de rencontrer une valeur dans un intervalle donné en lien avec la formule montrée ci-dessous :</p>
<p><span class="math display">\[p(X | \mu, \sigma) = \frac{1}{\sqrt{2\pi}\sigma} exp(-\frac{(X-\mu)^2}{2\sigma^2}),\]</span>
<span class="math inline">\(p(X | \mu, \sigma)\)</span> étant la densité de probabilité correspondant à la valeur <span class="math inline">\(X\)</span>. Il s’agit bien ici de la densité de probabilité, et non pas de la valeur de la probabilité d’obtenir une valeur précise. Pour mieux comprendre les valeurs que donne cette loi mathématique, regardons la Figure <a href="pr%C3%A9requis-1.html#fig:distiNorm">6.2</a> (graphique de gauche). Sur cette figure, la courbe noire représente les valeurs données par la fonction définissant la loi normale avec <span class="math inline">\(\mu\)</span> = 1, et <span class="math inline">\(\sigma\)</span> = 1. Ces valeurs en réalité n’ont pas vraiment d’intérêt en soi. Par contre, elle permettent de délimiter une aire (en rouge) entre elles et l’axe horizontal, la valeur de cette aire étant pour le coup la probabilité d’obtenir une valeur incluse dans l’intervalle de valeurs relatif à l’aire sous la courbe considérée. Ainsi, l’aire sous l’ensemble de la courbe représentant la densité de probabilité est associée à une probabilité de 1 (il y a par définition, lors d’un tirage au sort, 100 % de chances de rencontrer une valeur située entre le minimum et le maximum de la variable modélisée à l’aide de cette loi). Dans la même veine, le graphique de droite de la Figure <a href="pr%C3%A9requis-1.html#fig:distiNorm">6.2</a> montre une aire sous la courbe (en rouge) dont la valeur est la probabilité d’obtenir une valeur comprise en 2 et 3 lorsqu’on tire au sort une observation en provenance de la population représentée par une loi normale de moyenne 1 et d’écart-type 1, la probabilité étant ici de 14 %.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:distiNorm"></span>
<img src="Analyser-des-donne%CC%81es-avec-R_files/figure-html/distiNorm-1.png" alt="Densité de probabilité d'une loi normale" width="90%"><p class="caption">
Figure 6.2: Densité de probabilité d’une loi normale
</p>
</div>
<p>Plusieurs fonctions R peuvent être utilisées pour obtenir des informations liées à la distribution d’une loi normale donnée. Ces fonctions sont montrées ci-dessous.</p>
<div class="sourceCode" id="cb257"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fonction pour déterminer la densité de probabilité correspondant à la valeur x</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">1</span>, mean <span class="op">=</span> <span class="fl">1</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.3989423</code></pre>
<div class="sourceCode" id="cb259"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fonction pour déterminer la probabilité d'obtenir une valeur inférieure ou </span></span>
<span><span class="co"># égale à q</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span>q <span class="op">=</span> <span class="fl">2</span>, mean <span class="op">=</span> <span class="fl">1</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.8413447</code></pre>
<div class="sourceCode" id="cb261"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fonction pour déterminer la valeur pour laquelle il y a une probabilité p </span></span>
<span><span class="co"># d'obtenir une valeur inférieure ou égale à la valeur définie</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span>p <span class="op">=</span> <span class="fl">0.7</span>, mean <span class="op">=</span> <span class="fl">1</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 1.524401</code></pre>
<p>La loi normale peut être mise en lien avec d’autres grandes lois, telles que :</p>
<ul>
<li><p>La loi Chi-carré (<span class="math inline">\(\chi^2\)</span>) : lorsque l’on prend les valeurs de plusieurs distributions normales standards (avec des moyennes de 0 et des écarts-types de 1), qu’on les met au carré, puis qu’on les additionne, on obtient une variable suivant une loi <span class="math inline">\(\chi^2\)</span> à <span class="math inline">\(k\)</span> degrés de liberté (cf. Figure <a href="pr%C3%A9requis-1.html#fig:VariousQuantLaws">6.3</a>, graphique A), <span class="math inline">\(k\)</span> étant le nombre de variables que l’on a mises au carré. Comme on peut le voir sur la Figure <a href="pr%C3%A9requis-1.html#fig:VariousQuantLaws">6.3</a>, la distribution <span class="math inline">\(\chi^2\)</span> est plutôt asymétrique, avec des valeurs toujours supérieures à 0.</p></li>
<li><p>La loi <span class="math inline">\(t\)</span> : les distributions relatives à des lois <span class="math inline">\(t\)</span> ressemblent aux distributions relatives à des lois normales mais avec des queues de distribution plus épaisses (cf. Figure <a href="pr%C3%A9requis-1.html#fig:VariousQuantLaws">6.3</a>, graphique B). Une distribution <span class="math inline">\(t\)</span> peut être obtenue en divisant les valeurs d’une distribution <span class="math inline">\(\chi^2\)</span> par le nombre de degrés de liberté <span class="math inline">\(k\)</span>, puis en prenant leurs racines carrées, et enfin en divisant les valeurs d’une loi normale par la variable obtenue. On obtient alors une distribution <span class="math inline">\(t\)</span> à <span class="math inline">\(k\)</span> degrés de liberté (cf. Figure <a href="pr%C3%A9requis-1.html#fig:VariousQuantLaws">6.3</a>, graphique C).</p></li>
<li><p>La loi <span class="math inline">\(F\)</span> : la distribution d’une loi <span class="math inline">\(F\)</span> ressemble à celle d’une loi <span class="math inline">\(\chi^2\)</span>. Une distribution <span class="math inline">\(F\)</span> sert à comparer deux distributions <span class="math inline">\(\chi^2\)</span>.</p></li>
</ul>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:VariousQuantLaws"></span>
<img src="Analyser-des-donne%CC%81es-avec-R_files/figure-html/VariousQuantLaws-1.png" alt="Densité de probabilité de lois chi-carré, t, et F" width="100%"><p class="caption">
Figure 6.3: Densité de probabilité de lois chi-carré, t, et F
</p>
</div>
</div>
</div>
<div id="loi-des-grands-nombres-distribution-déchantillonnage-de-la-moyenne-et-théorème-de-la-limite-centrale" class="section level2" number="6.3">
<h2>
<span class="header-section-number">6.3</span> Loi des grands nombres, distribution d’échantillonnage de la moyenne, et théorème de la limite centrale<a class="anchor" aria-label="anchor" href="#loi-des-grands-nombres-distribution-d%C3%A9chantillonnage-de-la-moyenne-et-th%C3%A9or%C3%A8me-de-la-limite-centrale"><i class="fas fa-link"></i></a>
</h2>
<p>La loi des grands nombres décrit un principe de probabilité permettant de comprendre bon nombre de phénomènes statistiques, notamment lorsque l’on s’intéresse à la moyenne d’un échantillon. Cette loi implique par exemple le fait que la moyenne d’un échantillon pris au hasard dans une population tend à être plus proche de la moyenne de la population à mesure que la taille de l’échantillon étudié est grande. Cette loi est illustrée sur la Figure <a href="pr%C3%A9requis-1.html#fig:GreatNumLaw">6.4</a>. Sur cette figure, les distributions représentent des échantillons crées de manière aléatoire à partir d’une population ayant pour moyenne 0 et pour écart-type 400. Le trait vertical rouge représente la moyenne de la population d’origine alors que le trait en pointillés noirs montre la moyenne de l’échantillon qui a été obtenue. Lorsqu’on regarde chaque colonne de la figure du haut vers le bas et qu’on compare les colonnes entre elles, on se rend compte effectivement que plus la taille <span class="math inline">\(N\)</span> de l’échantillon tiré de la population est grande, plus le trait noir se retrouve en général proche du trait rouge, cela traduisant le fait qu’on a de meilleures chances que la moyenne de l’échantillon étudié soit plus proche de la moyenne de la population lorsque l’échantillon est de grande taille. Une question qui pourrait alors se poser est le nombre de personnes ou d’individus que doit contenir l’échantillon pour obtenir un résultat avec une marge d’erreur jugée acceptable.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:GreatNumLaw"></span>
<img src="Analyser-des-donne%CC%81es-avec-R_files/figure-html/GreatNumLaw-1.png" alt="Illustration de la loi des grands nombres avec la moyenne d'un échantillon. Les distributions ont été obtenues à partir de $N$ valeurs obtenues aléatoirement à partir d'une population de moyenne 0 et d'écart-type 400. Trait rouge = moyenne de la population d'origine ; trait noir = moyenne de l'échantillon" width="100%"><p class="caption">
Figure 6.4: Illustration de la loi des grands nombres avec la moyenne d’un échantillon. Les distributions ont été obtenues à partir de <span class="math inline">\(N\)</span> valeurs obtenues aléatoirement à partir d’une population de moyenne 0 et d’écart-type 400. Trait rouge = moyenne de la population d’origine ; trait noir = moyenne de l’échantillon
</p>
</div>
<p>La Figure <a href="pr%C3%A9requis-1.html#fig:GreatNumLaw">6.4</a> montre certes qu’on a plus de chances d’avoir une moyenne d’échantillon proche de la moyenne de la population avec un grand <span class="math inline">\(N\)</span>, mais elle esquisse aussi, avec les traits en pointillés noirs, le fait qu’avec un grand <span class="math inline">\(N\)</span>, la variabilité des valeurs que peuvent prendre les moyennes de plusieurs échantillons diminue. Pour s’en assurer, on peut chercher à voir les valeurs de moyennes que l’on obtiendrait si l’on étudiait un grand nombre d’échantillons (e.g., 10 000) de même taille, autrement dit la distribution d’échantillonnage de la moyenne pour une valeur de <span class="math inline">\(N\)</span> donnée. La Figure <a href="pr%C3%A9requis-1.html#fig:CentralLimTheo">6.5</a> donne une vision de ce que serait une telle distribution pour différentes valeurs de <span class="math inline">\(N\)</span> dans ce cas là.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:CentralLimTheo"></span>
<img src="Analyser-des-donne%CC%81es-avec-R_files/figure-html/CentralLimTheo-1.png" alt="Illustration du théorème de la limite centrale appliqué à une moyenne d'échantillon. Les distributions des moyennes montrées ici ont été obtenues avec 10 000 échantillons de N observations obtenues aléatoirement à partir d'une population ayant pour moyenne 0 et écart-type 400. Trait rouge = moyenne de la population d'origine" width="80%"><p class="caption">
Figure 6.5: Illustration du théorème de la limite centrale appliqué à une moyenne d’échantillon. Les distributions des moyennes montrées ici ont été obtenues avec 10 000 échantillons de N observations obtenues aléatoirement à partir d’une population ayant pour moyenne 0 et écart-type 400. Trait rouge = moyenne de la population d’origine
</p>
</div>
<p>La Figure <a href="pr%C3%A9requis-1.html#fig:CentralLimTheo">6.5</a> illustre plusieurs principes qui relèvent du <strong>théorème de la limite centrale</strong>, à savoir : la moyenne d’une distribution d’échantillonnage de la moyenne tend à être la même moyenne que celle de la population d’origine ; et l’écart-type de la distribution d’échantillonnage de la moyenne (<em>SEM</em>, pour <em>Standard Error of the Mean</em> en anglais), devient plus faible à mesure que <span class="math inline">\(N\)</span> grandit. Un troisième principe est illustré sur la Figure <a href="pr%C3%A9requis-1.html#fig:CentralLimTheo2">6.6</a>. Pour réaliser cette figure, la même démarche que pour la Figure <a href="pr%C3%A9requis-1.html#fig:CentralLimTheo">6.5</a> a été suivie, si ce n’est qu’auparavant, la population d’origine suivait systématiquement une loi normale. Dans le cas de la Figure <a href="pr%C3%A9requis-1.html#fig:CentralLimTheo2">6.6</a>, la population suit à l’origine une loi chi-carré, elle est donc asymétrique. Malgré tout, on voit que dès que <span class="math inline">\(N\)</span> est suffisamment grand, la distribution d’échantillonnage de la moyenne suit une loi normale.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:CentralLimTheo2"></span>
<img src="Analyser-des-donne%CC%81es-avec-R_files/figure-html/CentralLimTheo2-1.png" alt="Illustration du théorème de la limite centrale appliqué à une moyenne d'échantillon. Les distributions des moyennes montrées ici ont été obtenues avec 10 000 échantillons de N observations obtenues aléatoirement à partir d'une population suivant une loi chi-carré avec 3 degrés de liberté. Trait rouge = moyenne de la population d'origine" width="80%"><p class="caption">
Figure 6.6: Illustration du théorème de la limite centrale appliqué à une moyenne d’échantillon. Les distributions des moyennes montrées ici ont été obtenues avec 10 000 échantillons de N observations obtenues aléatoirement à partir d’une population suivant une loi chi-carré avec 3 degrés de liberté. Trait rouge = moyenne de la population d’origine
</p>
</div>
<p>Si l’on formalise les choses d’un point de vue plus mathématique, le théorème de la limite centrale nous dit que si une population a une moyenne <span class="math inline">\(\mu\)</span> et un écart-type <span class="math inline">\(\sigma\)</span>, alors la moyenne de la distribution d’échantillonnage a aussi <span class="math inline">\(\mu\)</span> comme moyenne, et l’écart-type de la distribution d’échantillonnage de la moyenne (i.e., l’erreur standard, <em>SEM</em>) vaut :</p>
<p><span class="math display">\[SEM = \frac{\sigma}{\sqrt{N}}.\]</span></p>
<p>La formule montre bien que pour une population présentant un écart-type donné, plus les échantillons étudiés seront de petite taille (<span class="math inline">\(N\)</span>), plus grande sera la variabilité des moyennes provenant des différents échantillons. D’un point de vue plus pratique, cela veut dire notamment que dans une méta-analyse où l’on chercherait à estimer par exemple la moyenne de l’effet d’une intervention dans une population donnée, on aura beau avoir plusieurs d’études conduites sur le sujet, si elles sont de trop petites tailles, il y a de bonnes chances pour que les valeurs des effets trouvés divergent substantiellement et ne permettent donc pas d’avoir une vue précise, fiable, de la valeur de l’effet concernant la population globale.</p>
</div>
<div id="résumé-3" class="section level2" number="6.4">
<h2>
<span class="header-section-number">6.4</span> Résumé<a class="anchor" aria-label="anchor" href="#r%C3%A9sum%C3%A9-3"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>Les lois de probabilité, la loi des grands nombres, la distribution d’échantillonnage d’une statistique, ou encore le théorème de la limite centrale, sont des outils mathématiques qui permettent de réaliser et de mieux comprendre les inférences statistiques.</li>
<li>Une loi de probabilité renseigne sur les chances, pour une statistique donnée, d’obtenir une valeur précise (e.g., un nombre de succès dans le cas d’une binomiale) ou d’obtenir une valeur tombant dans un rang de valeurs donné (e.g., s’agissant d’une moyenne dans le cas d’une loi normale).</li>
<li>Des exemples de lois de probabilité couramment utilisées sont la loi binomiale, la loi normale, la loi <span class="math inline">\(\chi^2\)</span>, la loi <span class="math inline">\(t\)</span>, et la loi <span class="math inline">\(F\)</span>.</li>
<li>Selon la loi des grands nombres, plus la taille d’un échantillon est grande, plus il y a de chances que la moyenne de cet échantillon soit relativement proche de la moyenne de la population d’origine.</li>
<li>Selon le théorème de la limite centrale, la moyenne de la distribution d’échantillonnage de la moyenne est la même valeur que la moyenne de la population d’origine, et l’écart-type de cette distribution (<span class="math inline">\(SEM\)</span>) est tel que : <span class="math inline">\(SEM = \frac{\sigma}{N}.\)</span> Par conséquent, plus <span class="math inline">\(N\)</span> est grand, plus <span class="math inline">\(SEM\)</span> est petite.</li>
</ul>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="r%C3%A9gressions.html"><span class="header-section-number">5</span> Régressions</a></div>
<div class="next"><a href="tests-statistiques-pour-des-variables-qualitatives.html"><span class="header-section-number">7</span> Tests statistiques pour des variables qualitatives</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#pr%C3%A9requis-1"><span class="header-section-number">6</span> Prérequis</a></li>
<li><a class="nav-link" href="#pr%C3%A9ambule"><span class="header-section-number">6.1</span> Préambule</a></li>
<li>
<a class="nav-link" href="#lois-de-probabilit%C3%A9"><span class="header-section-number">6.2</span> Lois de probabilité</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#notion-de-loi-de-probabilit%C3%A9"><span class="header-section-number">6.2.1</span> Notion de loi de probabilité</a></li>
<li><a class="nav-link" href="#la-loi-binomiale"><span class="header-section-number">6.2.2</span> La loi binomiale</a></li>
<li><a class="nav-link" href="#la-loi-normale-et-lois-apparent%C3%A9es"><span class="header-section-number">6.2.3</span> La loi normale et lois apparentées</a></li>
</ul>
</li>
<li><a class="nav-link" href="#loi-des-grands-nombres-distribution-d%C3%A9chantillonnage-de-la-moyenne-et-th%C3%A9or%C3%A8me-de-la-limite-centrale"><span class="header-section-number">6.3</span> Loi des grands nombres, distribution d’échantillonnage de la moyenne, et théorème de la limite centrale</a></li>
<li><a class="nav-link" href="#r%C3%A9sum%C3%A9-3"><span class="header-section-number">6.4</span> Résumé</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/pydemull/Analyser-des-donnees-avec-R/blob/master/06-Statistical_theory.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/pydemull/Analyser-des-donnees-avec-R/edit/master/06-Statistical_theory.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Analyser des données avec R</strong>" was written by Pierre-Yves de Müllenheim. It was last built on 2023-11-06.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
